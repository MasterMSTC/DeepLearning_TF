{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gr5rEFvREr7J"
   },
   "source": [
    "# Font-type Recognition with <font color=gree>CNN / ConvNets : Convolutional Neural Networks</font> using <font color= #b30047>[Keras](https://keras.io/)</font>\n",
    "\n",
    "![Keras logo](https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png)\n",
    "\n",
    "\n",
    "# * [MSTC](http://mstc.ssr.upm.es/big-data-track) and MUIT: <font size=5 color='green'>Deep Learning with Tensorflow & Keras</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GttLBSJYEr7M"
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cNzfwXAtZoLH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8ZfzBwlIEr7X"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm, tqdm_notebook\n",
    "except ImportError:\n",
    "    def tqdm(x, *args, **kwargs):\n",
    "        return x\n",
    "      \n",
    "print('Keras version: ',keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEmv5qV9cVjD"
   },
   "source": [
    "## <font color= #00cc00>Next cells load the Font Type dataset:</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "sAId6_gMcTXN"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load and data\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from six.moves import urllib\n",
    "\n",
    "file_url = 'https://github.com/bloolizard/PlayWithTensorFlow/raw/master/data_with_labels.npz'\n",
    "file_name = 'data_with_labels.npz'\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(file_url, file_name)\n",
    "    \n",
    "    \n",
    "# Load data\n",
    "data = np.load('data_with_labels.npz')\n",
    "\n",
    "train = data['arr_0']/255.\n",
    "labels = data['arr_1']\n",
    "\n",
    "onehot= to_categorical(labels, num_classes=len(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8QqY9fOdcpq1"
   },
   "source": [
    "## Preparing Train/Test Data :\n",
    "- ### Random Permutation! + split data into training / validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qAf7zER3clns"
   },
   "outputs": [],
   "source": [
    "# Split data into training (90%) and validation (10%)\n",
    "np.random.seed(100)\n",
    "\n",
    "indices = np.random.permutation(train.shape[0])\n",
    "\n",
    "valid_cnt = int(train.shape[0] * 0.1)\n",
    "\n",
    "test_idx, training_idx = indices[:valid_cnt],\\\n",
    "                         indices[valid_cnt:]\n",
    "  \n",
    "test, train = train[test_idx,:],\\\n",
    "              train[training_idx,:]\n",
    "  \n",
    "onehot_test, onehot_train = onehot[test_idx,:],\\\n",
    "                        onehot[training_idx,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kGQTLlOHmaps"
   },
   "outputs": [],
   "source": [
    "train=train.reshape([-1,train.shape[1],train.shape[2],1])\n",
    "test=test.reshape([-1,test.shape[1],test.shape[2],1])\n",
    "\n",
    "print('Train shape=', train.shape , '\\nTest shape=', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tUMpFuaWdIiW"
   },
   "source": [
    "## Try CNN / ConvNet models in Keras (remember):\n",
    "\n",
    "1.   **Define your model**. Create a sequence and add layers.\n",
    "2.   **Compile your model**. Specify loss functions and optimizers\n",
    "3.   **Fit your model**. Execute the model using data.\n",
    "4.   **Make predictions**. Use the model to generate predictions on new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hfmJQuxXdtLZ"
   },
   "source": [
    "## 1.   **Define your ConNet model**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5_5aE1fid8VC"
   },
   "source": [
    "## ...a model similar as the one we used in TensorFlow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Q01af97Bdy8B"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import MaxPooling2D, Dropout, Dense, Flatten\n",
    "\n",
    "from keras.layers import Convolution2D as Conv2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# input: 36x36 images with 1 channel -> (36, 36) tensors.\n",
    "# this applies 4 convolution filters of size 5x5 each.\n",
    "model.add(Conv2D(4, (5, 5), activation='relu', input_shape=(36, 36,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5cA7pFmTg9Y6"
   },
   "source": [
    "## <font color=green> You can try other  ConvNet styles: i.e. VGG style\n",
    "  \n",
    "  [ConvNet Arquitectures](https://medium.com/@siddharthdas_32104/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5)\n",
    "  \n",
    "  **CNNs Architectures: LeNet, AlexNet, VGG, GoogLeNet, ResNet and more â€¦**\n",
    "\n",
    "    The ImageNet project is a large visual database designed for use in visual object recognition software research. The ImageNet project runs an annual software contest, the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), where software programs compete to correctly classify and detect objects and scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WXIqh42Ag4Bt"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 36x36 images with 1 channel -> (36, 36) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(36, 36,1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aoQoXnpMeZxu"
   },
   "source": [
    "## 2.   **Compile your model**. Specify loss functions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wDba0-nieY3k"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OvxG1cgfevRz"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yylapSuewSk"
   },
   "source": [
    "# 3.   **Fit your model**. Train the model using data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "--hQW5Ode4H-"
   },
   "outputs": [],
   "source": [
    "# history to analyze training history evolution\n",
    "\n",
    "#history=model.fit(train, onehot_train,\n",
    "#         epochs=100,\n",
    "#         batch_size=128,\n",
    "#         verbose=1)\n",
    "\n",
    "# validation_data allows to see evaluation on test while training\n",
    "history=model.fit(train, onehot_train,\n",
    "         epochs=100,\n",
    "         batch_size=128,\n",
    "         validation_data=(test, onehot_test),\n",
    "         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dBGWDJ06fDNd"
   },
   "source": [
    "## 4.   **Make predictions**. Use the model to generate predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Q7CZPGT8fE9e"
   },
   "outputs": [],
   "source": [
    "# Check accuracy on train set\n",
    "\n",
    "loss_train, accuracy_train = model.evaluate(train, onehot_train, batch_size=128)\n",
    "\n",
    "\n",
    "print('\\nTraining Accuracy=', accuracy_train)\n",
    "\n",
    "# Check accuracy on test set\n",
    "\n",
    "loss, accuracy = model.evaluate(test, onehot_test, batch_size=128)\n",
    "\n",
    "\n",
    "print('\\nTest Accuracy=', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DFbgE1QBfUIP"
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2oQdaeiJf0pd"
   },
   "outputs": [],
   "source": [
    "print('Train Accuracy: ',np.round(history.history['acc'][-1],2))\n",
    "print('Test_Accuracy: ',np.round(history.history['val_acc'][-1],2))\n",
    "\n",
    "# Plot the accuracy curves\n",
    "plt.plot(history.history['acc'],'bo')\n",
    "plt.plot(history.history['val_acc'],'rX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ucT89yZ_f-ip"
   },
   "source": [
    "# Get predictions / probabilities ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Z48r7BWTf9pA"
   },
   "outputs": [],
   "source": [
    "pred_probabilities= model.predict(test)\n",
    "\n",
    "print('First Five Probs.:\\n',pred_probabilities[0:5])\n",
    "\n",
    "print('\\n\\nFirst Five Classes:\\n',onehot_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4jgiEniXBz1"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aH0mRInNEr-5"
   },
   "outputs": [],
   "source": [
    "!pip install pandas_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cdIA7SA7Er-9"
   },
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "ConfMatrix=ConfusionMatrix(np.argmax(onehot_test,1), np.argmax(pred_probabilities,1))\n",
    "\n",
    "ConfMatrix.plot(normalized=True,backend='seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0pywIJeXEr_C"
   },
   "outputs": [],
   "source": [
    "ConfMatrix.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "onbbqWnfZYqO"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "\n",
    "ConfMatrix=cm(np.argmax(onehot_test,1), np.argmax(pred_probabilities,1))\n",
    "\n",
    "print('Confusion Matrix:\\n',ConfMatrix)\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(ConfMatrix, annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "ax.xaxis.set_ticklabels(['FT_1', 'FT_2','FT_3','FT_4','FT_5'])\n",
    "ax.yaxis.set_ticklabels(['FT_1', 'FT_2','FT_3','FT_4','FT_5']);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "MSTC_Keras_FontReco_CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
