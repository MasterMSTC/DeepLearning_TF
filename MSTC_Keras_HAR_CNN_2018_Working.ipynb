{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MSTC_Keras_HAR_CNN_2018_Working.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"gr5rEFvREr7J","colab_type":"text"},"cell_type":"markdown","source":["# Time series classification with Tensorflow & <font color=red>Keras</font> using <font color= #70e514>CNN / ConvNets</font>\n","\n","## $HAR$ : Humman Activity Recognition\n","\n","## Example form:\n","\n","## Time series classification with Tensorflow burakhimmetoglu August 22, 2017\n","(https://burakhimmetoglu.com/2017/08/22/time-series-classification-with-tensorflow/)\n","\n","<img src=https://burakhimmetoglu.files.wordpress.com/2017/08/ekg-158177_640.png height=\"200\" width=\"260\">\n","\n","\n","\n","* <font size=5 color='green'>[MSTC](http://mstc.ssr.upm.es/big-data-track) seminar on Deep Learning, Tensorflow & Keras</font>\n","\n"]},{"metadata":{"id":"HWTwxevN3jH5","colab_type":"text"},"cell_type":"markdown","source":["## See Notebooks in GitHub [healthDataScience](https://github.com/healthDataScience)  : $deep-learning-HAR$\n","\n","\n","![healthDataScience](https://avatars2.githubusercontent.com/u/30838413?s=200&v=4)"]},{"metadata":{"id":"GttLBSJYEr7M","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["! pip install --upgrade tqdm\n","\n","try:\n","    from tqdm import tqdm, tqdm_notebook\n","except ImportError:\n","    def tqdm(x, *args, **kwargs):\n","        return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qz37JkKlph0Q","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["! pip install --upgrade keras"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4SYfnKS25NjY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Imports\n","import numpy as np\n","import os\n","\n","import keras\n","import math\n","\n","\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"72eQqPkZ6fGV","colab_type":"text"},"cell_type":"markdown","source":["## Some UTILITY functions"]},{"metadata":{"id":"Jp440cvv6fo9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","import pandas as pd \n","import numpy as np\n","import os\n","\n","\n","def standardize(train, test):\n","\t\"\"\" Standardize data \"\"\"\n","\n","\t# Standardize train and test\n","\tX_train = (train - np.mean(train, axis=0)[None,:,:]) / np.std(train, axis=0)[None,:,:]\n","\tX_test = (test - np.mean(test, axis=0)[None,:,:]) / np.std(test, axis=0)[None,:,:]\n","\n","\treturn X_train, X_test\n","\n","def one_hot(labels, n_class = 6):\n","\t\"\"\" One-hot encoding \"\"\"\n","\texpansion = np.eye(n_class)\n","\ty = expansion[:, labels-1].T\n","\tassert y.shape[1] == n_class, \"Wrong number of labels!\"\n","\n","\treturn y\n","\n","\n","def get_batches(X, y, batch_size = 100):\n","\t\"\"\" Return a generator for batches \"\"\"\n","\tn_batches = len(X) // batch_size\n","\tX, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n","\n","\t# Loop over batches and yield\n","\tfor b in range(0, len(X), batch_size):\n","\t\tyield X[b:b+batch_size], y[b:b+batch_size]\n","\t\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EG24e11v4_Pr","colab_type":"text"},"cell_type":"markdown","source":["# Human Activity Recognition (HAR) Dataset\n","## From: [UCI Repository](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)\n","\n"]},{"metadata":{"id":"Mi5WA9JiNPzc","colab_type":"text"},"cell_type":"markdown","source":["## Reading data already prepared from orignal UCI Dataset from a Shared Google Drive npz file"]},{"metadata":{"id":"KB-E_TTXLuZw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["! pip install googledrivedownloader"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2-9QCoaIL2kw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","gdd.download_file_from_google_drive(file_id='1VLgB0CK8DjMJ4gstLRC0gA2pVGXy-RYa',\n","                                    dest_path='./UCI_HAR_Dataset_Drive.npz',\n","                                    unzip=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AuSlWeOGKXNh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["npzfile = np.load('UCI_HAR_Dataset_Drive.npz')\n","npzfile.files\n","\n","X_train=npzfile['arr_0']\n","X_test=npzfile['arr_1']\n","labels_train=npzfile['arr_2']\n","labels_test=npzfile['arr_3']\n","\n","print('Training data size: ',X_train.shape)\n","print('Test data size: ',X_test.shape)\n","\n","print('Training labels size: ',labels_train.shape)\n","print('Test labels size: ',labels_test.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K7XotXfnQMmA","colab_type":"text"},"cell_type":"markdown","source":["## Six categories (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING).\n","\n","[LSTM-Human-Activity-Recognition](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition)\n","\n","    The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used."]},{"metadata":{"id":"w_buet_NQ4ga","colab_type":"text"},"cell_type":"markdown","source":["## ... see some labels...\n","\n","WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING"]},{"metadata":{"id":"qlI_Rg0tKjV0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["plt.plot(labels_train[50:250])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NOZWGTx8Q93u","colab_type":"text"},"cell_type":"markdown","source":["## ...see some signals..."]},{"metadata":{"id":"-YFZL3VcSDJH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["plt.subplots(nrows = 3, figsize = (15, 10), sharex = True)\n","plt.subplot(3,1,1)\n","plt.plot(X_train[50,:,0])\n","plt.plot(X_train[50,:,1])\n","plt.plot(X_train[50,:,2])\n","\n","plt.subplot(3,1,2)\n","plt.plot(X_train[80,:,3])\n","plt.plot(X_train[80,:,4])\n","plt.plot(X_train[80,:,5])\n","\n","plt.subplot(3,1,3)\n","plt.plot(X_train[110,:,0])\n","plt.plot(X_train[110,:,1])\n","plt.plot(X_train[110,:,2])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iYERYfiMh6-6","colab_type":"text"},"cell_type":"markdown","source":["## One-hot-encoding of Labels"]},{"metadata":{"id":"2uS8kLK4KWXz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["y_train = one_hot(labels_train)\n","y_test = one_hot(labels_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_ne97jSfnMxC","colab_type":"text"},"cell_type":"markdown","source":["## Re-Shape for 2D Conv (1 D??)"]},{"metadata":{"id":"BqMJAmKWpMVI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["X_train=X_train.reshape([X_train.shape[0],X_train.shape[1],X_train.shape[2],1])\n","X_test=X_test.reshape([X_test.shape[0],X_test.shape[1],X_test.shape[2],1])\n","\n","print('Train shape=', X_train.shape , '\\nTest shape=', X_test.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gahVlpqriMuY","colab_type":"text"},"cell_type":"markdown","source":["\n","## 1.   **Define your ConvNet model**:\n"]},{"metadata":{"id":"-IZKXH4BiYUQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","from keras.models import Sequential\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6BwzLFi2sK1Q","colab_type":"text"},"cell_type":"markdown","source":["## 2.   **Compile your model**. Specify loss functions and optimizers"]},{"metadata":{"id":"pw_-jKLBjAH8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from keras.optimizers import ..."],"execution_count":0,"outputs":[]},{"metadata":{"id":"zYKg8cw-s9bb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JsC0RVBgt6Ng","colab_type":"text"},"cell_type":"markdown","source":["# 3.   **Fit your model**. Train the model using data."]},{"metadata":{"id":"gtERijSzjpkR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U1_QY8xRuXCu","colab_type":"text"},"cell_type":"markdown","source":["## 4.   **Make predictions**. Use the model to generate predictions on new data."]},{"metadata":{"id":"TDA1gIl2ke_o","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["print('\\nTraining Accuracy=', accuracy_train)\n","print('\\nTest Accuracy=', accuracy)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OeEm5C53uzql","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Plot the accuracy history curves\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KJG5nGzFvPf7","colab_type":"text"},"cell_type":"markdown","source":["## Confusion Matrix"]}]}