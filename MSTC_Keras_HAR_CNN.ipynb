{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSTC_Keras_HAR_CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "gr5rEFvREr7J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Time series classification with Tensorflow & <font color=red>Keras</font> using <font color= #70e514>CNN / ConvNets</font>\n",
        "\n",
        "## $HAR$ : Humman Activity Recognition\n",
        "\n",
        "## Example form:\n",
        "\n",
        "## Time series classification with Tensorflow burakhimmetoglu - August 22, 2017\n",
        "(https://burakhimmetoglu.com/2017/08/22/time-series-classification-with-tensorflow/)\n",
        "\n",
        "![](https://burakhimmetoglu.files.wordpress.com/2017/08/ekg-158177_640.png)\n",
        "\n",
        "\n",
        "# * [MSTC](http://mstc.ssr.upm.es/big-data-track) and MUIT: <font size=5 color='green'>Deep Learning with Tensorflow & Keras</font>"
      ]
    },
    {
      "metadata": {
        "id": "HWTwxevN3jH5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## See Notebooks in GitHub [healthDataScience](https://github.com/healthDataScience)  : $deep-learning-HAR$\n",
        "\n",
        "\n",
        "![healthDataScience](https://avatars2.githubusercontent.com/u/30838413?s=200&v=4)"
      ]
    },
    {
      "metadata": {
        "id": "GttLBSJYEr7M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install --upgrade tqdm\n",
        "\n",
        "try:\n",
        "    from tqdm import tqdm, tqdm_notebook\n",
        "except ImportError:\n",
        "    def tqdm(x, *args, **kwargs):\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qz37JkKlph0Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4SYfnKS25NjY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "72eQqPkZ6fGV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Some UTILITY functions"
      ]
    },
    {
      "metadata": {
        "id": "Jp440cvv6fo9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "def one_hot(labels, n_class = 6):\n",
        "\t\"\"\" One-hot encoding \"\"\"\n",
        "\texpansion = np.eye(n_class)\n",
        "\ty = expansion[:, labels-1].T\n",
        "\tassert y.shape[1] == n_class, \"Wrong number of labels!\"\n",
        "\n",
        "\treturn y\n",
        "\t\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EG24e11v4_Pr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Human Activity Recognition (HAR) Dataset\n",
        "## From: [UCI Repository](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Mi5WA9JiNPzc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reading data already prepared from orignal UCI Dataset from a Shared Google Drive npz file"
      ]
    },
    {
      "metadata": {
        "id": "KB-E_TTXLuZw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install googledrivedownloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2-9QCoaIL2kw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1VLgB0CK8DjMJ4gstLRC0gA2pVGXy-RYa',\n",
        "                                    dest_path='./UCI_HAR_Dataset_Drive.npz',\n",
        "                                    unzip=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AuSlWeOGKXNh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "npzfile = np.load('UCI_HAR_Dataset_Drive.npz')\n",
        "npzfile.files\n",
        "\n",
        "X_train=npzfile['arr_0']\n",
        "X_test=npzfile['arr_1']\n",
        "labels_train=npzfile['arr_2']\n",
        "labels_test=npzfile['arr_3']\n",
        "\n",
        "print('Training data size: ',X_train.shape)\n",
        "print('Test data size: ',X_test.shape)\n",
        "\n",
        "print('Training labels size: ',labels_train.shape)\n",
        "print('Test labels size: ',labels_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K7XotXfnQMmA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Six categories (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING).\n",
        "\n",
        "[LSTM-Human-Activity-Recognition](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition)\n",
        "\n",
        "    The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used."
      ]
    },
    {
      "metadata": {
        "id": "w_buet_NQ4ga",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ... see some labels...\n",
        "\n",
        "WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING"
      ]
    },
    {
      "metadata": {
        "id": "qlI_Rg0tKjV0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(labels_train[50:250])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NOZWGTx8Q93u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ...see some signals..."
      ]
    },
    {
      "metadata": {
        "id": "-YFZL3VcSDJH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.subplots(nrows = 3, figsize = (15, 10), sharex = True)\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(X_train[50,:,0])\n",
        "plt.plot(X_train[50,:,1])\n",
        "plt.plot(X_train[50,:,2])\n",
        "\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(X_train[80,:,3])\n",
        "plt.plot(X_train[80,:,4])\n",
        "plt.plot(X_train[80,:,5])\n",
        "\n",
        "plt.subplot(3,1,3)\n",
        "plt.plot(X_train[110,:,0])\n",
        "plt.plot(X_train[110,:,1])\n",
        "plt.plot(X_train[110,:,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iYERYfiMh6-6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One-hot-encoding of Labels"
      ]
    },
    {
      "metadata": {
        "id": "2uS8kLK4KWXz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = one_hot(labels_train)\n",
        "y_test = one_hot(labels_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ne97jSfnMxC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Re-Shape for 2D Conv (1 D??)"
      ]
    },
    {
      "metadata": {
        "id": "BqMJAmKWpMVI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train=X_train.reshape([X_train.shape[0],X_train.shape[1],X_train.shape[2],1])\n",
        "X_test=X_test.reshape([X_test.shape[0],X_test.shape[1],X_test.shape[2],1])\n",
        "\n",
        "print('Train shape=', X_train.shape , '\\nTest shape=', X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gahVlpqriMuY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1.   **Define your ConNet model**:\n"
      ]
    },
    {
      "metadata": {
        "id": "-IZKXH4BiYUQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import MaxPooling2D, Dropout, Dense, Flatten\n",
        "\n",
        "from keras.layers import Convolution2D as Conv2D\n",
        "\n",
        "model = Sequential()\n",
        "# input: 128x9 images with 1 channel -> (128, 9) tensors.\n",
        "# this applies 18 convolution filters of size 2x2 each.\n",
        "model.add(Conv2D(18, (2, 2), activation='relu', input_shape=(128, 9,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(6, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6BwzLFi2sK1Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.   **Compile your model**. Specify loss functions and optimizers"
      ]
    },
    {
      "metadata": {
        "id": "pw_-jKLBjAH8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zYKg8cw-s9bb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JsC0RVBgt6Ng",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3.   **Fit your model**. Train the model using data."
      ]
    },
    {
      "metadata": {
        "id": "gtERijSzjpkR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# validation_data allows to see evaluation on test while training\n",
        "history=model.fit(X_train, y_train,\n",
        "         epochs=100,\n",
        "         batch_size=128,\n",
        "         validation_data=(X_test, y_test),\n",
        "         verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U1_QY8xRuXCu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.   **Make predictions**. Use the model to generate predictions on new data."
      ]
    },
    {
      "metadata": {
        "id": "TDA1gIl2ke_o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Check accuracy on train set\n",
        "\n",
        "loss_train, accuracy_train = model.evaluate(X_train, y_train, batch_size=128)\n",
        "\n",
        "\n",
        "print('\\nTraining Accuracy=', accuracy_train)\n",
        "\n",
        "# Check accuracy on test set\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, batch_size=128)\n",
        "\n",
        "\n",
        "print('\\nTest Accuracy=', accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OeEm5C53uzql",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Train Accuracy: ',np.round(history.history['acc'][-1],2))\n",
        "print('Test_Accuracy: ',np.round(history.history['val_acc'][-1],2))\n",
        "\n",
        "# Plot the accuracy curves\n",
        "plt.plot(history.history['acc'],'bo')\n",
        "plt.plot(history.history['val_acc'],'rX')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7RhuMn3flca8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get predictions / probabilities ..."
      ]
    },
    {
      "metadata": {
        "id": "xlpzDd1xlQfe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred_probabilities= model.predict(X_test)\n",
        "\n",
        "print('First Five Probs.:\\n',pred_probabilities[0:5])\n",
        "\n",
        "print('\\n\\nFirst Five Classes:\\n',y_test[0:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJG5nGzFvPf7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "metadata": {
        "id": "JhoS3dDRvTtl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install pandas_ml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oe0qI1-ava3L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pandas_ml import ConfusionMatrix\n",
        "\n",
        "ConfMatrix=ConfusionMatrix(np.argmax(y_test,1), np.argmax(pred_probabilities,1))\n",
        "\n",
        "ConfMatrix.plot(normalized=True,backend='seaborn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4IvPCcp1veQG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ConfMatrix.print_stats()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}