{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MSTC_FontReco_CNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"gr5rEFvREr7J","colab_type":"text"},"cell_type":"markdown","source":["## Font type Recognition using <font color= #70e514>CNN / ConvNets : Convolutional Neural Networks</font>\n","\n","### Example form:\n","![Deep Learning with TensorFlow by Dan Van Boxel (Packt Video)](https://img1.od-cdn.com/ImageType-400/6135-1/67E/936/4A/%7B67E9364A-5248-4174-917C-549ED505ABC6%7DImg400.jpg)\n","\n","# * [MSTC](http://mstc.ssr.upm.es/big-data-track) and MUIT: <font size=5 color='green'>Deep Learning with Tensorflow & Keras</font>\n","\n"]},{"metadata":{"id":"GttLBSJYEr7M","colab_type":"code","colab":{}},"cell_type":"code","source":["! pip install --upgrade tqdm"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8ZfzBwlIEr7X","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import math\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","\n","try:\n","    from tqdm import tqdm, tqdm_notebook\n","except ImportError:\n","    def tqdm(x, *args, **kwargs):\n","        return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JHdsHmlrEr7f","colab_type":"text"},"cell_type":"markdown","source":["### All the steps for preparing training/tresting data\n","\n","* Data: 2790 36x36 images"]},{"metadata":{"id":"VQyrNBBjEr7h","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","Load data\n","\"\"\"\n","\n","import os\n","from six.moves import urllib\n","\n","file_url = 'https://github.com/bloolizard/PlayWithTensorFlow/raw/master/data_with_labels.npz'\n","file_name = 'data_with_labels.npz'\n","\n","if not os.path.exists(file_name):\n","    urllib.request.urlretrieve(file_url, file_name)\n","    \n","    \n","data = np.load('data_with_labels.npz')\n","train = data['arr_0']/255.\n","labels = data['arr_1']\n","\n","\n","\n","def to_onehot(labels,nclasses = 5):\n","    '''\n","    Convert labels to \"one-hot\" format.\n","    >>> a = [0,1,2,3]\n","    >>> to_onehot(a,5)\n","    array([[ 1.,  0.,  0.,  0.,  0.],\n","           [ 0.,  1.,  0.,  0.,  0.],\n","           [ 0.,  0.,  1.,  0.,  0.],\n","           [ 0.,  0.,  0.,  1.,  0.]])\n","    '''\n","    outlabels = np.zeros((len(labels),nclasses))\n","    for i,l in enumerate(labels):\n","        outlabels[i,l] = 1\n","    return outlabels\n","\n","onehot = to_onehot(labels)\n","\n","# Split data into training (90%) and validation (10%)\n","\n","np.random.seed(100)\n","\n","indices = np.random.permutation(train.shape[0])\n","\n","valid_cnt = int(train.shape[0] * 0.1)\n","\n","test_idx, training_idx = indices[:valid_cnt],\\\n","                         indices[valid_cnt:]\n","\n","test, train = train[test_idx,:],\\\n","              train[training_idx,:]\n","\n","onehot_test, onehot_train = onehot[test_idx,:],\\\n","                        onehot[training_idx,:]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-J5b_CvJEr7p","colab_type":"text"},"cell_type":"markdown","source":["# CNN graph definition"]},{"metadata":{"id":"WGg0toD0Er7r","colab_type":"code","colab":{}},"cell_type":"code","source":["# These will be inputs\n","## Input pixels, image with one channel (gray)\n","x = tf.placeholder(\"float\", [None, 36, 36])\n","\n","# Note that -1 is for reshaping\n","#if our image was RBG (3 color channels) last dimension of shape should be 3\n","# NOTE:\n","#           tf.nn.conv2d the input tensor has 4 dimensions: [batch, height, width, channels],\n","#           the convolution operates on a 2D window on the height, width dimensions.\n","\n","x_im = tf.reshape(x, [-1,36,36,1])\n","\n","## Known labels\n","y_ = tf.placeholder(\"float\", [None,5])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jtt_SmkSEr7w","colab_type":"code","colab":{}},"cell_type":"code","source":["# Conv layer 1\n","num_filters = 4 #also known as kernels \n","winx = 5\n","winy = 5\n","\n","W1 = tf.Variable(tf.truncated_normal(\n","    [winx, winy, 1 , num_filters],\n","    stddev=1./math.sqrt(winx*winy)))\n","\n","b1 = tf.Variable(tf.constant(0.1,\n","                shape=[num_filters]))\n","\n","# winx times winy (5x5) convolution, pad with zeros on edges\n","\n","### Strides [1, Val2, Val3, 1] for convnets\n","#\n","#   The first 1 is the batch: You don't usually want to skip over examples in your batch,\n","#   The last 1 is the depth of the convolution: You don't usually want to skip inputs\n","#   Val2 and Val3 and they represent the overlap in application of the\n","#   convolutional filters along rows and columns\n","\n","### Padding\n","#\n","#   VALID: Don't apply any padding\n","#   SAME: Apply padding to input (if needed) so that input image gets fully\n","#         covered by filter and stride you specified.\n","#          For stride 1, this will ensure that output image size is same as input\n","\n","xw = tf.nn.conv2d(x_im, W1,\n","                  strides=[1, 1, 1, 1],\n","                  padding='SAME')\n","\n","h1 = tf.nn.relu(xw + b1)\n","\n","# 2x2 Max pooling, no padding on edges\n","p1 = tf.nn.max_pool(h1, ksize=[1, 2, 2, 1],\n","        strides=[1, 2, 2, 1], padding='VALID')\n","\n","# Need to flatten convolutional output for use in dense layer\n","p1_size = np.product(\n","          [s.value for s in p1.get_shape()[1:]])\n","\n","p1f = tf.reshape(p1, [-1, p1_size ])\n","\n","# Dense layer\n","num_hidden = 32\n","W2 = tf.Variable(tf.truncated_normal(\n","     [p1_size, num_hidden],\n","     stddev=2./math.sqrt(p1_size)))\n","\n","b2 = tf.Variable(tf.constant(0.2,\n","     shape=[num_hidden]))\n","\n","h2 = tf.nn.relu(tf.matmul(p1f,W2) + b2)\n","\n","# Output Layer\n","W3 = tf.Variable(tf.truncated_normal(\n","     [num_hidden, 5],\n","     stddev=1./math.sqrt(num_hidden)))\n","\n","b3 = tf.Variable(tf.constant(0.1,shape=[5]))\n","\n","# This placeholder is to feed dropout info into the Graph\n","keep_prob = tf.placeholder(\"float\")\n","h2_drop = tf.nn.dropout(h2, keep_prob)\n","\n","# Just initialize\n","init=tf.global_variables_initializer()\n","\n","\n","# Define model\n","y = tf.matmul(h2_drop,W3) + b3\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qPhsrRXaEr71","colab_type":"text"},"cell_type":"markdown","source":["### ... end model specification, begin training code"]},{"metadata":{"id":"m1TFmrj0Er74","colab_type":"code","colab":{}},"cell_type":"code","source":["# Loss function: cross-entropy\n","cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y + 1e-50, labels=y_))\n","\n","# How we train\n","train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n","\n","# Define accuracy\n","correct_prediction = tf.equal(tf.argmax(y,1),\n","                              tf.argmax(y_,1))\n","\n","accuracy = tf.reduce_mean(tf.cast(\n","           correct_prediction, \"float\"))\n","\n","#...we calculate probabilities to explore the confusion matrix\n","preds=tf.nn.softmax(y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pPA0PwChEr8A","colab_type":"text"},"cell_type":"markdown","source":["## Train..."]},{"metadata":{"id":"vNN1gYnuEr8C","colab_type":"code","colab":{}},"cell_type":"code","source":["# Actually train\n","epochs = 1500\n","train_acc = np.zeros(epochs//10)\n","test_acc = np.zeros(epochs//10)\n","\n","with tf.Session() as sess:\n","  \n","  sess.run(init)\n","\n","  for i in tqdm(range(epochs)):\n","    # Record summary data, and the accuracy\n","    if i % 10 == 0:  \n","        # Check accuracy on train set\n","        A = accuracy.eval(feed_dict={x: train,\n","            y_: onehot_train, keep_prob: 1.0})\n","        train_acc[i//10] = A\n","        # And now the validation set\n","        A = accuracy.eval(feed_dict={x: test,\n","            y_: onehot_test, keep_prob: 1.0})\n","        test_acc[i//10] = A\n","    train_step.run(feed_dict={x: train,\n","        y_: onehot_train, keep_prob: 0.75})\n","\n","  cnn_test_pred=sess.run(preds,feed_dict={x: test,\n","            y_: onehot_test, keep_prob: 1.0})\n","  \n","  p1_out,p1f_out,h1_out=sess.run([p1, p1f, h1],feed_dict={x: test,\n","            y_: onehot_test, keep_prob: 1.0})\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"HnoxdiwSfc5x","colab_type":"code","colab":{}},"cell_type":"code","source":["print('h1 shape: ',h1_out.shape)\n","print('p1 shape: ',p1_out.shape)\n","print('p1f shape: ',p1f_out.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"80DOR91VgPB6","colab_type":"code","colab":{}},"cell_type":"code","source":["p1f_out.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oUjvVooHg29a","colab_type":"code","colab":{}},"cell_type":"code","source":["18*18*4"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xLwiYlMpWBUI","colab_type":"code","colab":{}},"cell_type":"code","source":["# Notice that accuracy flattens out\n","print('Train Accuracy: ',np.round(train_acc[-1],2))\n","print('Test_Accuracy: ',np.round(test_acc[-1],2))\n","\n","# Plot the accuracy curves\n","plt.plot(train_acc,'bo')\n","plt.plot(test_acc,'rX')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r4jgiEniXBz1","colab_type":"text"},"cell_type":"markdown","source":["## Confusion Matrix"]},{"metadata":{"id":"aH0mRInNEr-5","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install pandas_ml"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cdIA7SA7Er-9","colab_type":"code","colab":{}},"cell_type":"code","source":["from pandas_ml import ConfusionMatrix\n","\n","ConfMatrix=ConfusionMatrix(np.argmax(onehot_test,1), np.argmax(cnn_test_pred,1))\n","\n","ConfMatrix.plot(normalized=True,backend='seaborn')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0pywIJeXEr_C","colab_type":"code","colab":{}},"cell_type":"code","source":["ConfMatrix.print_stats()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"onbbqWnfZYqO","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import confusion_matrix as cm\n","\n","ConfMatrix=cm(np.argmax(onehot_test,1), np.argmax(cnn_test_pred,1))\n","\n","print('Confusion Matrix:\\n',ConfMatrix)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZyQs2zLdZgko","colab_type":"code","colab":{}},"cell_type":"code","source":["import seaborn as sns\n","\n","ax= plt.subplot()\n","sns.heatmap(ConfMatrix, annot=True, ax = ax); #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","\n","ax.xaxis.set_ticklabels(['FT_1', 'FT_2','FT_3','FT_4','FT_5'])\n","ax.yaxis.set_ticklabels(['FT_1', 'FT_2','FT_3','FT_4','FT_5']);"],"execution_count":0,"outputs":[]}]}