{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFntciKlhH1C"
   },
   "source": [
    "#  From <font color='organge'>\"manual\"</font> learning to <font color='brown'>\"machine\"</font> learning\n",
    "## A Simple linear classifier in [TensorFlow](https://www.tensorflow.org/) (logistic regression)\n",
    "\n",
    "![Image TensorFlow](https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/TensorFlowLogo.svg/220px-TensorFlowLogo.svg.png)\n",
    "\n",
    "\n",
    "* <font size=5 color='green'>[MSTC](http://mstc.ssr.upm.es/big-data-track) Introduction to Deep Learning using Tensorflow & Keras</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sS2gcP7GhH1R"
   },
   "source": [
    "### Generate two-class artificial data using $numpy$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2RCIyLn-jwzl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of data per-class\n",
    "Ndata_class=100\n",
    "\n",
    "group1 = np.random.multivariate_normal([-4, -4], 20*np.identity(2), size=Ndata_class)\n",
    "group2 = np.random.multivariate_normal([4, 4], 20*np.identity(2), size=Ndata_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "THoIQGbM3Iqn"
   },
   "outputs": [],
   "source": [
    "group1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DTux-wz9j7Et"
   },
   "source": [
    "#<font color= #b717ab>?? ... plot our data...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2qskzBDboC3T"
   },
   "outputs": [],
   "source": [
    "# TO DO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LqeBl8-akbT6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(group1[:,0],group1[:,1])\n",
    "plt.scatter(group2[:,0],group2[:,1],color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EcGshEKJhH1a"
   },
   "outputs": [],
   "source": [
    "# Plot artificial data\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.scatter(group1[:,0],group1[:,1])\n",
    "plt.scatter(group2[:,0],group2[:,1],color='g')\n",
    "plt.xlabel('x1',fontsize=18)\n",
    "plt.ylabel('x2',fontsize=18)\n",
    "plt.title('Artificial Data',fontsize=18)\n",
    "plt.grid(color='k', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hpk6OlXUhH1m"
   },
   "source": [
    "## <font color='organge'>\"manual\"</font> linear discrimination\n",
    "* w2\\*x2 + w1\\*x1 + w0 = 0\n",
    "<br>or,  with w2=1\n",
    "* x2 = -w1*x1 - w0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZgfA-11cxh26"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ... try with some coefficients..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VO5lM1UalGwB"
   },
   "source": [
    "### <font color= #b717ab>?? ... plot the line (hyper plane)...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "X7GdsZI1n-7z"
   },
   "outputs": [],
   "source": [
    "# TO DO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "R4Ei_4MZhH1o"
   },
   "outputs": [],
   "source": [
    "x1 = np.arange(-15, 15, 0.1)\n",
    "\n",
    "w2=1\n",
    "\n",
    "w0=5\n",
    "w1=1\n",
    "#w1=1.0\n",
    "\n",
    "x2= - w1 * x1 - w0 \n",
    "\n",
    "plt.plot(x1,x2,linestyle='-.',color='red')\n",
    "\n",
    "x2= - w1 * x1 - w0 +2\n",
    "plt.plot(x1,x2,'green')\n",
    "\n",
    "x2= - w1 * x1 - w0 - 2\n",
    "plt.plot(x1,x2,'blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_xLan16nhH1t"
   },
   "outputs": [],
   "source": [
    "# Plot linear discrimination\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(group1[:,0],group1[:,1])\n",
    "plt.scatter(group2[:,0],group2[:,1],color='g')\n",
    "plt.plot(x1,x2,color='r')\n",
    "\n",
    "mult=3\n",
    "plt.quiver([w1*mult],[w2*mult], angles='xy', scale_units='xy', scale=1)\n",
    "\n",
    "plt.xlabel('x1',fontsize=18)\n",
    "plt.ylabel('x2',fontsize=18)\n",
    "plt.title('Linear Discrimination',fontsize=18)\n",
    "plt.grid(color='k', linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LeN549YeoWoO"
   },
   "source": [
    "#<font color= #b717ab>?? ... \"where\" is the [w1, w2] vector??...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GzdPjZtzqbdi"
   },
   "outputs": [],
   "source": [
    "# TRY plot the [w1,w2] vector in the scatter plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vH30VmENyF18"
   },
   "outputs": [],
   "source": [
    "# ... insert this to plot coef vector [w1,w2]\n",
    "\n",
    "'''\n",
    "mult=3\n",
    "plt.quiver([w1*mult],[w2*mult], angles='xy', scale_units='xy', scale=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkXt37LNhH12"
   },
   "source": [
    "### Classification based on the distance to the line\n",
    "\n",
    "* w2\\*x2 + w1\\*x1 + w0 > 0  'green' points\n",
    "* w2\\*x2 + w1\\*x1 + w0 < 0  'blue' points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "f7Qyfo63rO-Y"
   },
   "outputs": [],
   "source": [
    "train_X = np.vstack((group1, group2))\n",
    "\n",
    "# make \"predictions\" of class 0 or 1\n",
    "# pred = w2*x2 + w1*x1 + w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-H8Bs6Cmq03s"
   },
   "outputs": [],
   "source": [
    "\n",
    "pred=np.dot(train_X,np.array([w1,w2])) + w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iGKfUVO-rGvQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(pred)\n",
    "plt.xlabel('x1',fontsize=18)\n",
    "plt.ylabel('x2',fontsize=18)\n",
    "plt.title('Classification: < 0 \\'blue\\' > 1 \\'green\\' ',fontsize=18)\n",
    "plt.grid(color='k', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xmhS_LkPhH14"
   },
   "outputs": [],
   "source": [
    "train_X = np.vstack((group1, group2)) \n",
    "pred= w1*train_X[:,0] + w2*train_X[:,1] + w0\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(pred)\n",
    "plt.xlabel('x1',fontsize=18)\n",
    "plt.ylabel('x2',fontsize=18)\n",
    "plt.title('Classification: < 0 \\'blue\\' > 1 \\'green\\' ',fontsize=18)\n",
    "plt.grid(color='k', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jvyg0F60hH2D"
   },
   "source": [
    "### let's make these values \"probabilities\" using the $sigmoid$ function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VBU58W5ihH2F"
   },
   "outputs": [],
   "source": [
    "x = np.arange(-10, 11)\n",
    "plt.title('Sigmoid : logistic function',fontsize=18)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$p(X)=1/(1+exp(-x))$',fontsize=16)\n",
    "plt.plot(x, (1/(1+np.exp(-x))));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2oyzikyhH2V"
   },
   "source": [
    "####     Prediction using the $logistic$ or $sigmoid$ function \n",
    "* $p(X) = 1/(1 + \\exp(x))$, taking values between $0$ and $1$.\n",
    "\n",
    "* $p(X)$ represents the probability that the point $X$ should be labelled \"green\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HwzT1SA5vN2j"
   },
   "source": [
    "#<font color= #b717ab>?? apply sigmoid to our predictions in \"pred\".... and plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "a8u1grfzv_ZW"
   },
   "outputs": [],
   "source": [
    "# TO DO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yxV9GRWIvbwc"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(sigmoid(pred))\n",
    "#plt.plot((1/(1+np.exp(-pred))))\n",
    "\n",
    "plt.ylim(-0.02, 1.02)\n",
    "\n",
    "plt.title('Class-probabilities',fontsize=18)\n",
    "plt.xlabel('$pred$',fontsize=16)\n",
    "plt.ylabel('$p(X)=1/(1+exp(-pred))$',fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wrCgCeWBhH2X"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "plt.plot((1/(1+np.exp(-pred))))\n",
    "plt.ylim(-0.02, 1.02)\n",
    "\n",
    "plt.title('Class-probabilities',fontsize=18)\n",
    "plt.xlabel('$pred$',fontsize=16)\n",
    "plt.ylabel('$p(X)=1/(1+exp(-pred))$',fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqi9-4lnhH2k"
   },
   "source": [
    "# NOW let's use cross-entropy loss function\n",
    "$$-\\sum_{i=1}^n l(X_i) \\log(p(X_i)) + (1-l(X_i))\\log(1-p(X_i)),$$\n",
    "<br>\n",
    "where $l(X_i)$ is the label of $X_i$ (which is $0$ for 'blue' or $1$ for 'green').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xBjPtk2fhH2l"
   },
   "outputs": [],
   "source": [
    "train_labels = np.array([0.0] * Ndata_class + [1.0] * Ndata_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6iPd00PwhCB"
   },
   "source": [
    "#<font color= #b717ab>?? can you obtain the cross-entropy loss function ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dal6wSj6wrlP"
   },
   "outputs": [],
   "source": [
    "# Cost function is cross-entropy\n",
    "# TO DO...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "thkvoCpfhH2s"
   },
   "outputs": [],
   "source": [
    "# Cost function is cross-entropy\n",
    "pred_prob=(1/(1+np.exp(-pred)))\n",
    "cost = -np.sum((train_labels) * np.log(pred_prob + 1e-10) + (1-train_labels) * np.log(1-pred_prob + 1e-10))\n",
    "\n",
    "print(\"cross-entropy: {}\".format(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTSyggf-xG2K"
   },
   "source": [
    "#<font color= #b717ab>?? ... and now the more interprtable Accuraccy (Classification Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TUhc303LxXWU"
   },
   "outputs": [],
   "source": [
    "# TO DO : acuraccy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ovF9CTaIhH21"
   },
   "outputs": [],
   "source": [
    "Accuracy=np.sum((pred_prob>0.5).astype(int) == train_labels)/(len(pred_prob)*1.0)\n",
    "\n",
    "print(\"Classification Accuracy = \",Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9iUnBLChH28"
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Now we will use <font color= #FF5733 >TensorFlow</font> (using graphs) for:\n",
    "\n",
    "- ## Feeding data into a \"given\" linear classifier with $sigmoid$ output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgDowBWyzFzL"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## first import TensorfLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fstdzR9AzE6m"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "sXg5nqW9hH2_"
   },
   "outputs": [],
   "source": [
    "### GRAPH DEFINITION\n",
    "\n",
    "# PLACEHOLDERS:\n",
    "# Inputs are now two-dimensional and come with labels \"blue\" or \"green\" (represented by 0 or 1)\n",
    "X = tf.placeholder(\"float\", shape=[None, 2])\n",
    "labels = tf.placeholder(\"float\", shape=[None])\n",
    "\n",
    "\n",
    "# Set model weights and bias as before\n",
    "#W = tf.Variable(tf.ones([2, 1], \"float\"), name=\"weight\")\n",
    "#b = tf.Variable(tf.zeros([1], \"float\"), name=\"bias\")\n",
    "\n",
    "\n",
    "W=tf.constant([w1,w2],\"float\",shape=[2,1],name=\"weights\")\n",
    "b=tf.constant(np.float(w0),\"float\",name=\"bias\")\n",
    "\n",
    "\n",
    "# Predictor is now the logistic function\n",
    "#pred_tf = tf.sigmoid(tf.to_double(tf.reduce_sum(tf.matmul(X, W), axis=[1]) + b))\n",
    "pred_tf = tf.sigmoid(tf.to_double(tf.reduce_sum(tf.matmul(X, W),1)+b))\n",
    "\n",
    "# Cost function is cross-entropy\n",
    "cost_tf = -tf.reduce_sum(tf.to_double(labels) * tf.log(pred_tf) + (1-tf.to_double(labels)) * tf.log(1-pred_tf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlF8ZrygylWF"
   },
   "source": [
    "### you can see details of [tf.reduce_sum](https://www.tensorflow.org/api_docs/python/tf/reduce_sum)\n",
    "\n",
    "    Computes the sum of elements across dimensions of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ukjgwui3hH3G"
   },
   "outputs": [],
   "source": [
    "### GRAPH EXECUTION\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "#init = tf.initialize_all_variables()\n",
    "\n",
    "# We stack our two groups of 2-dimensional points\n",
    "train_X = np.vstack((group1, group2))\n",
    "\n",
    "# labels to feed them\n",
    "train_labels = np.array([0.0] * Ndata_class + [1.0] * Ndata_class)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    pred_out, cost_out=sess.run([pred_tf, cost_tf], feed_dict={X: train_X, labels: train_labels})\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9N55Adv8hH3P"
   },
   "outputs": [],
   "source": [
    "print(\"cross-entropy: {}\".format(cost_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "I3ysOnxThH3m"
   },
   "outputs": [],
   "source": [
    "Accuracy=np.sum((pred_out>0.5).astype(int) == train_labels)/(len(pred_out)*1.0)\n",
    "\n",
    "print(\"Classification Accuracy = \",Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cv-m0wbDhH3s"
   },
   "source": [
    "# Now let's train!\n",
    "\n",
    "\n",
    "\n",
    "*   Both $W$ and $b$ are now <font size=4 color=green> variables</font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "m__uHgZ5hH3t"
   },
   "outputs": [],
   "source": [
    "# Inputs are now two-dimensional and come with labels \"blue\" or \"green\" (represented by 0 or 1)\n",
    "X = tf.placeholder(\"float\", shape=[None, 2])\n",
    "labels = tf.placeholder(\"float\", shape=[None])\n",
    "\n",
    "# Set model weights and bias as before\n",
    "W = tf.Variable(tf.zeros([2, 1], \"float\"), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([1], \"float\"), name=\"bias\")\n",
    "\n",
    "# Predictor is now the logistic function\n",
    "pred_tf = tf.sigmoid(tf.to_double(tf.reduce_sum(tf.matmul(X, W),1) + b))\n",
    "\n",
    "\n",
    "# Cost function is cross-entropy\n",
    "cost_tf = -tf.reduce_sum(tf.to_double(labels) * tf.log(pred_tf) + (1-tf.to_double(labels)) * tf.log(1-pred_tf))\n",
    "\n",
    "# Gradient descent\n",
    "learning_rate = 0.00001\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "#init = tf.initialize_all_variables()\n",
    "\n",
    "# We stack our two groups of 2-dimensional points\n",
    "train_X = np.vstack((group1, group2))\n",
    "\n",
    "# labels to feed them\n",
    "train_labels = np.array([0.0] * Ndata_class + [1.0] * Ndata_class)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # We can Run the optimization algorithm several times\n",
    "    for i in range(10):\n",
    "        \n",
    "        cost_out,W_out,b_out,pred_out,_=sess.run([cost_tf, W,b, pred_tf, optimizer], feed_dict={X: train_X, labels: train_labels})\n",
    "        print(\"\\n***** Epoch : %d \\n Cost= %s \"%(i,cost_out))\n",
    "        print(\"Weights= \",format(W_out))\n",
    "        print(\"bias= \",format(b_out))\n",
    "        \n",
    "        Accuracy=np.sum((pred_out>0.5).astype(int) == train_labels)/(len(pred_out)*1.0)\n",
    "\n",
    "        print(\"Classification Accuracy = \",Accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WQfPDBCRhH4G"
   },
   "source": [
    "### Now we train using batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Bpe9JNc-hH4K"
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "n_samples=Ndata_class*2\n",
    "batch_size=40\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # We stack our two groups of 2-dimensional points and label them 0 and 1 respectively\n",
    "    train_X = np.vstack((group1, group2))\n",
    "\n",
    "    # labels to feed them\n",
    "    train_labels = np.array([0.0] * Ndata_class + [1.0] * Ndata_class)\n",
    "\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    # Run the optimization algorithm 1000 times\n",
    "    for i in range(1000):\n",
    "        # Select random minibatch\n",
    "        indices = np.random.choice(n_samples, batch_size)\n",
    "        X_batch, labels_batch = train_X[indices], train_labels[indices]\n",
    "        sess.run(optimizer, feed_dict={X: X_batch, labels: labels_batch})\n",
    "\n",
    "        \n",
    "    # Plot the predictions: the values of p\n",
    "    Xmin = np.min(train_X)-1\n",
    "    Xmax = np.max(train_X)+1\n",
    "    x = np.arange(Xmin, Xmax, 0.1)\n",
    "    y = np.arange(Xmin, Xmax, 0.1)\n",
    "    \n",
    "\n",
    "    plt.scatter(group1.T[0][:],group1.T[1][:])\n",
    "    plt.scatter(group2.T[0][:],group2.T[1][:],color='g')\n",
    "    plt.xlim(Xmin, Xmax)\n",
    "    plt.ylim(Xmin, Xmax)\n",
    "    print('W = ', sess.run(W))\n",
    "    print('b = ', sess.run(b))\n",
    "    \n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    predictions = sess.run(pred, feed_dict={X: np.array((xx.ravel(), yy.ravel())).T})\n",
    "    \n",
    "    plt.title('Probability that model will label a given point \"green\"')\n",
    "    plt.contour(x, y, predictions.reshape(len(x), len(y)), cmap=cm.BuGn, levels=np.arange(0.0, 1.1, 0.1))\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0nALdxAhH4V"
   },
   "source": [
    "## Logistic regression in TensorFlow\n",
    "\n",
    "https://gist.github.com/fuglede/ad04ce38e80887ddcbeb6b81e97bbfbc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "07wEoayZhH4W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MSTC_IntroTF_2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
