{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MSTC_Keras_FontReco_FeedFordward.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"FsnDWHL0sYVC","colab_type":"text"},"cell_type":"markdown","source":["# Introduction to <font color= #b30047>[Keras](https://keras.io/)</font> using the Font type Recognition Example\n","\n","![Keras logo](https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png)\n","\n","\n","# * [MSTC](http://mstc.ssr.upm.es/big-data-track) and MUIT: <font size=5 color='green'>Deep Learning with Tensorflow & Keras</font>"]},{"metadata":{"id":"ZtDhN1TDcjU5","colab_type":"text"},"cell_type":"markdown","source":["## [Keras](https://keras.io/): The Python Deep Learning library\n","\n","Keras was initially developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System).\n","\n","**Keras (κέρας) means horn in Greek.**\n","\n","    In the Odyssey dream spirits are divided between those who deceive men with false visions, who arrive to Earth through a gate of ivory, and those who announce a future that will come to pass, who arrive through a gate of horn. \n","    \n"]},{"metadata":{"id":"Aqx_d0WzcqNi","colab_type":"text"},"cell_type":"markdown","source":["## Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano.\n","\n","**It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.**\n","\n","Guiding principles:\n","\n","-   User friendliness.\n","    \n","-   Modularity. A model is understood as a sequence or a graph of standalone, fully-configurable modules that can be plugged together with as little restrictions as possible.\n","\n","-   Easy extensibility. New modules are simple to add (as new classes and functions).\n","\n","-   Work with Python. Keras is compatible with: Python 2.7-3.6 .\n"]},{"metadata":{"id":"u9IQSXuzfrn3","colab_type":"text"},"cell_type":"markdown","source":["## Import <font color= #b30047>[Keras](https://keras.io/)</font> as Python package\n","\n","    Notice that we will use a TensorFlow backend"]},{"metadata":{"id":"XzN1CgeXVHoz","colab_type":"text"},"cell_type":"markdown","source":["## Now we don't need install keras and import as a separate library... (but can be done!)"]},{"metadata":{"id":"L3B6C9BZch3e","colab_type":"code","colab":{}},"cell_type":"code","source":["# https://keras.io/\n","#!pip install -q keras\n","#import keras"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9LNPji56SuQg","colab_type":"text"},"cell_type":"markdown","source":["---\n","\n","# [Tensorflow guide to Keras](https://www.tensorflow.org/guide/keras) $tf.keras$\n","\n","    import tf.keras\n","\n","* tf.keras is TensorFlow's implementation of the Keras API specification.\n","* This is a high-level API to build and train models that includes first-class support for TensorFlow-specific functionality, such as eager execution, tf.data pipelines, and Estimators.\n","* tf.keras makes TensorFlow easier to use without sacrificing flexibility and performance.\n","\n","To get started, import tf.keras as part of your TensorFlow program setup:\n","\n","    import tensorflow as tf\n","    from tensorflow import keras\n","    \n","---\n","---\n"]},{"metadata":{"id":"8ty1PFvuUJEz","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pGZ56CJ7fot1","colab_type":"code","colab":{}},"cell_type":"code","source":["print(keras.__version__)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tcoipncfgUTP","colab_type":"text"},"cell_type":"markdown","source":["## <font color= #00cc00>Next cells load the Font Type dataset:</font>\n","\n","    ... same as in TensorFlow Notebook"]},{"metadata":{"id":"w7D2Lg7qivEO","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","# Import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hXShpFzLsYVe","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","Load and data\n","\"\"\"\n","\n","import os\n","from six.moves import urllib\n","\n","file_url = 'https://github.com/bloolizard/PlayWithTensorFlow/raw/master/data_with_labels.npz'\n","file_name = 'data_with_labels.npz'\n","\n","if not os.path.exists(file_name):\n","    urllib.request.urlretrieve(file_url, file_name)\n","    \n","    \n","# Load data\n","data = np.load('data_with_labels.npz')\n","\n","train = data['arr_0']/255.\n","labels = data['arr_1']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DrR66fIusYWm","colab_type":"text"},"cell_type":"markdown","source":["## Beyond Layers and Models [Keras](https://keras.io/) provides many usefull tools such as:\n","- ###  image and text preprocessing, metrics, Scikit-learn API, utilities, ... (see Keras Documentation)\n","### <font color= #00cc00>In the next cell:</font>\n","    One-Hot-Encoding of labels using Keras (see https://keras.io/utils/#to_categorical)"]},{"metadata":{"id":"lkN3llexsYWp","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.utils import to_categorical\n","onehot= to_categorical(labels, num_classes=len(np.unique(labels)))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ncDzoGpjsYWw","colab_type":"code","colab":{}},"cell_type":"code","source":["print(onehot[0:5])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vkSp2U6xsYW4","colab_type":"text"},"cell_type":"markdown","source":["### Permutation! + split data into training / validation"]},{"metadata":{"id":"B4uuj3dSsYW7","colab_type":"code","colab":{}},"cell_type":"code","source":[" \n","# Split data into training (90%) and validation (10%)\n","np.random.seed(100)\n","\n","indices = np.random.permutation(train.shape[0])\n","\n","valid_cnt = int(train.shape[0] * 0.1)\n","\n","test_idx, training_idx = indices[:valid_cnt],\\\n","                         indices[valid_cnt:]\n","  \n","test, train = train[test_idx,:],\\\n","              train[training_idx,:]\n","  \n","onehot_test, onehot_train = onehot[test_idx,:],\\\n","                        onehot[training_idx,:]\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ji22ODpBsYW_","colab_type":"code","colab":{}},"cell_type":"code","source":["print('Train shape=', train.shape , '\\nTest shape=', test.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6p4DW23OsYXG","colab_type":"text"},"cell_type":"markdown","source":["### Reshape to represent each image as a vector"]},{"metadata":{"id":"tJbeLPU_3BiI","colab_type":"code","colab":{}},"cell_type":"code","source":["train=train.reshape([-1,train.shape[1]*train.shape[2]])\n","test=test.reshape([-1,test.shape[1]*test.shape[2]])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"43yeILCwsYXS","colab_type":"code","colab":{}},"cell_type":"code","source":["print('Train shape=', train.shape , '\\nTest shape=', test.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jtj53ORjjRdJ","colab_type":"text"},"cell_type":"markdown","source":["# <font color= #b30047>[Keras](https://keras.io/) Models </font>\n","\n","- ## The core data structure of Keras is a model, a way to organize layers.\n"]},{"metadata":{"id":"p0yFwO2ymeE7","colab_type":"text"},"cell_type":"markdown","source":["## The construction of deep learning models in Keras is as follows:\n","\n","1.   **Define your model**. Create a sequence and add layers.\n","2.   **Compile your model**. Specify loss functions and optimizers\n","3.   **Fit your model**. Execute the model using data.\n","4.   **Make predictions**. Use the model to generate predictions on new data.\n","\n","\n","\n","\n"]},{"metadata":{"id":"EWITCRKznUUd","colab_type":"text"},"cell_type":"markdown","source":["## 1.   **Define your model**. Create a sequence and add layers.\n","\n","* The simplest type of model is the <font color= #b30047>**Sequential**</font> model: a linear stack of layers.\n","\n","For more complex architectures, you should use the <font color= #b30047>**Keras functional API**</font>, which allows to build arbitrary graphs of layers.\n"]},{"metadata":{"id":"bLXqeDjJkRyf","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.models import Sequential\n","\n","model = Sequential()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"N8rR2jqDkaNk","colab_type":"text"},"cell_type":"markdown","source":["\n","* Stacking layers is as easy as <font color= #b30047>**.add()**</font>\n","\n","      To stack layers you must first import the types of layers you want: in our case Dense (we could also add Dropout, Activation)\n","      "]},{"metadata":{"id":"kA2XZPG-384S","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.layers import Dense\n","\n","\n","model.add(Dense(128, activation='relu', input_dim=train.shape[1]))\n","# Dense(128) is a fully-connected layer with 128 hidden units.\n","# in the first layer, you must specify the expected input data shape:\n","# here, 1296-dimensional vectors.\n","\n","\n","model.add(Dense(32, activation='sigmoid'))\n","\n","## onehot_train.shape[1] is the number of classes\n","model.add(Dense(onehot_train.shape[1], activation='softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9m5gOnm14jD1","colab_type":"text"},"cell_type":"markdown","source":["### ... adding more layers is easy (try uncommenting options in this cell)"]},{"metadata":{"id":"Xq7gDDoJkUAz","colab_type":"code","colab":{}},"cell_type":"code","source":["#from keras.layers import Dense, Dropout, Activation\n","\n","\n","#model.add(Dense(128, activation='relu', input_dim=train.shape[1]))\n","## Dense(128) is a fully-connected layer with 128 hidden units.\n","## in the first layer, you must specify the expected input data shape:\n","3# here, 1296-dimensional vectors.\n","\n","#model.add(Dropout(0.5))\n","#model.add(Dense(32, activation='relu'))\n","\n","#model.add(Dense(32, activation='sigmoid'))\n","#model.add(Dropout(0.5))\n","\n","## onehot_train.shape[1] is the number of classes\n","#model.add(Dense(onehot_train.shape[1], activation='softmax'))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z-bCjXLcoLPH","colab_type":"text"},"cell_type":"markdown","source":["## Note that differently from TensorFlow:\n","\n","* Declaring the **input shape** is only required of the **first layer** – Keras is good enough to work out the size of the tensors flowing through the model from there.\n","\n","* We don’t have to declare any **weights** or **bias** variables like we do in TensorFlow."]},{"metadata":{"id":"Cy-LDXFBpPqr","colab_type":"text"},"cell_type":"markdown","source":["## We can now define what type of <font color= #b30047>**optimizer**</font> to use (i.e. gradient descent, Adam optimiser etc.).\n","\n","*  Although optimizer (and loss function) can be also defined when compiling the model.\n","\n"]},{"metadata":{"id":"RcrL1Y-ZsYXs","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.optimizers import SGD\n","\n","\n","sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rTm7k2H-sYX0","colab_type":"text"},"cell_type":"markdown","source":["## 2.   **Compile your model**. Specify loss functions and optimizers\n","\n","### FROM:\n","\n","![Long-Short-Term-Memory-Networks-With-Python](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/Long-Short-Term-Memory-Networks-With-Python.png)\n","<br>\n","*Once we have defined our network, we must compile it. Compilation is an eficiency step. It\n","transforms the simple sequence of layers that we defined into a highly eficient series of matrix\n","transforms in a format intended to be executed on your GPU or CPU, depending on how Keras\n","is configured. Think of compilation as a precompute step for your network. It is always required\n","after defining a model.*"]},{"metadata":{"id":"QpVUF_KesYX2","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=sgd,\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kHumGZrasYYA","colab_type":"text"},"cell_type":"markdown","source":["### Compilation requires a number of parameters to be specified, specifically tailored to training your network:\n","* the **optimization algorithm** to use to train the network \n","* and the **loss function** used to evaluate the network that is minimized by the optimization algorithm.\n","\n","      You can also specify metrics to collect while fitting your model in addition to the loss function. Generally, the most useful additional metric to collect is accuracy for classification problems (e.g. `accuracy' or `acc' for short). The metrics to collect are specified by name in an array of metric or loss function names, for example metrics=['accuracy']"]},{"metadata":{"id":"xHzpqbzFsYYB","colab_type":"code","colab":{}},"cell_type":"code","source":["model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ib0Vgzm_sYYg","colab_type":"code","colab":{}},"cell_type":"code","source":["32*128+32"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8JWiVSdtr3Z8","colab_type":"text"},"cell_type":"markdown","source":["## 3.   **Fit your model**. Train the model using data.\n","\n","* We first pass in all of our training data, in our case, *train* data and *OHE labels* onehot_train.\n","* The next argument is the batch size – we don’t have to explicitly handle the batching up of our data during training in Keras, rather we just specify the batch size and it does it for us (in this example batch size is 128)\n","\n","      However you can choose to feed batches to your model manually: model.train_on_batch(train_batch, onehot_train_batch)\n","\n","\n","* Next we pass the number of training epochs (20 in this case).\n","* A verbose flag, set to 1 here, specifies if you want detailed information being printed in the console about the progress of the training."]},{"metadata":{"id":"wZ6b-aJbsYYm","colab_type":"code","colab":{}},"cell_type":"code","source":["model.fit(train, onehot_train,\n","         epochs=100,\n","         batch_size=128,\n","         verbose=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rOflclIMsYYu","colab_type":"text"},"cell_type":"markdown","source":["## 4.   **Make predictions**. Use the model to generate predictions on new data.\n","\n","* The model evaluates the loss across all of the test data, as well as any other metrics specified when the model was compiled, like classification accuracy.\n","\n","* A list of evaluation metrics is returned. For example, for a model compiled with the accuracy metric, we could evaluate it on a new dataset.\n","\n","      Note that evaluation is done in batches"]},{"metadata":{"id":"J90MmNmfsYYv","colab_type":"code","colab":{}},"cell_type":"code","source":["# Check accuracy on train set\n","\n","loss, accuracy = model.evaluate(train, onehot_train, batch_size=128)\n","\n","\n","print('\\nTraining Accuracy=', accuracy)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"afuQ0aURsYY2","colab_type":"code","colab":{}},"cell_type":"code","source":["# Check accuracy on test set\n","\n","loss, accuracy = model.evaluate(test, onehot_test, batch_size=128)\n","\n","\n","print('\\nTest Accuracy=', accuracy)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qPRMYf3lwrgB","colab_type":"text"},"cell_type":"markdown","source":["# Get predictions / probabilities ..."]},{"metadata":{"id":"oPt8w4kW_zol","colab_type":"code","colab":{}},"cell_type":"code","source":["pred_probabilities= model.predict(test)\n","\n","print('First Five Probs.:\\n',pred_probabilities[0:5])\n","\n","print('\\n\\nFirst Five Classes:\\n',onehot_test[0:5])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"InFROWNm_FTd","colab_type":"text"},"cell_type":"markdown","source":["## Confusion Matrix"]},{"metadata":{"id":"c9fDzcdR_HAe","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install pandas_ml"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gQbue3n8_QHz","colab_type":"code","colab":{}},"cell_type":"code","source":["from pandas_ml import ConfusionMatrix\n","\n","ConfMatrix=ConfusionMatrix(np.argmax(onehot_test,1), np.argmax(pred_probabilities,1))\n","\n","ConfMatrix.plot(normalized=True,backend='seaborn')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CTVz5Jez_mOU","colab_type":"code","colab":{}},"cell_type":"code","source":["import seaborn as sns\n","\n","from sklearn.metrics import confusion_matrix as cm\n","\n","ConfMatrix=cm(np.argmax(onehot_test,1), np.argmax(pred_probabilities,1))\n","\n","print('Confusion Matrix:\\n',ConfMatrix)\n","\n","ax= plt.subplot()\n","sns.heatmap(ConfMatrix, annot=True, ax = ax); #annot=True to annotate cells\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","\n","ax.xaxis.set_ticklabels(['FT_1', 'FT_2','FT_3','FT_4','FT_5'])\n","ax.yaxis.set_ticklabels(['FT_1', 'FT_2','FT_3','FT_4','FT_5']);"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z2madRNH7I_F","colab_type":"text"},"cell_type":"markdown","source":["### ... you can also check *validation data* while training..."]},{"metadata":{"id":"IuVvTuNl7GZS","colab_type":"code","colab":{}},"cell_type":"code","source":["model.fit(train, onehot_train,\n","         epochs=10,\n","         batch_size=128,\n","         validation_data=(test, onehot_test),\n","         verbose=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WT9ZSduf-KFR","colab_type":"text"},"cell_type":"markdown","source":["## NOTE: that model.fit do not initialize training...\n","\n"]},{"metadata":{"id":"B9Vnh71d-JTu","colab_type":"code","colab":{}},"cell_type":"code","source":["# If you want initialize the model\n","\n","from keras import backend as K\n","def reset_weights(model):\n","    session = K.get_session()\n","    for layer in model.layers: \n","        if hasattr(layer, 'kernel_initializer'):\n","            layer.kernel.initializer.run(session=session)\n","            \n","reset_weights(model)\n","\n","model.fit(train, onehot_train,\n","         epochs=10,\n","         batch_size=128,\n","         validation_data=(test, onehot_test),\n","         verbose=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yBjjd3Epw0j0","colab_type":"text"},"cell_type":"markdown","source":["## ... you can also get useful **History** info..."]},{"metadata":{"id":"UcR8ZEuzCPh6","colab_type":"code","colab":{}},"cell_type":"code","source":["reset_weights(model)\n","\n","history=model.fit(train, onehot_train,\n","         epochs=100,\n","         batch_size=128,\n","         validation_data=(test, onehot_test),\n","         verbose=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tSbZG1liB4-D","colab_type":"code","colab":{}},"cell_type":"code","source":["print(history.history.keys())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z5quW77uCXY0","colab_type":"code","colab":{}},"cell_type":"code","source":["print('Train Accuracy: ',np.round(history.history['acc'][-1],2))\n","print('Test_Accuracy: ',np.round(history.history['val_acc'][-1],2))\n","\n","# Plot the accuracy curves\n","plt.plot(history.history['acc'],'bo')\n","plt.plot(history.history['val_acc'],'rX')"],"execution_count":0,"outputs":[]}]}