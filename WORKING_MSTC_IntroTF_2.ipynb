{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WORKING_MSTC_IntroTF_2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"cFntciKlhH1C","colab_type":"text"},"cell_type":"markdown","source":["#  From <font color='organge'>\"manual\"</font> learning to <font color='brown'>\"machine\"</font> learning\n","## A Simple linear classifier in [TensorFlow](https://www.tensorflow.org/) (logistic regression)\n","\n","![Image TensorFlow](https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/TensorFlowLogo.svg/220px-TensorFlowLogo.svg.png)\n","\n","\n","* <font size=5 color='green'>[MSTC](http://mstc.ssr.upm.es/big-data-track) Introduction to Deep Learning using Tensorflow & Keras</font>"]},{"metadata":{"id":"sS2gcP7GhH1R","colab_type":"text"},"cell_type":"markdown","source":["### Generate two-class artificial data using $numpy$"]},{"metadata":{"id":"2RCIyLn-jwzl","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","# Number of data per-class\n","Ndata_class=100\n","\n","group1 = np.random.multivariate_normal([-4, -4], 20*np.identity(2), size=Ndata_class)\n","group2 = np.random.multivariate_normal([4, 4], 20*np.identity(2), size=Ndata_class)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"THoIQGbM3Iqn","colab_type":"code","colab":{}},"cell_type":"code","source":["group1.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DTux-wz9j7Et","colab_type":"text"},"cell_type":"markdown","source":["#<font color= #b717ab>?? ... plot our data...."]},{"metadata":{"id":"2qskzBDboC3T","colab_type":"code","colab":{}},"cell_type":"code","source":["# TO DO..."],"execution_count":0,"outputs":[]},{"metadata":{"id":"Hpk6OlXUhH1m","colab_type":"text"},"cell_type":"markdown","source":["## <font color='organge'>\"manual\"</font> linear discrimination\n","* w2\\*x2 + w1\\*x1 + w0 = 0\n","<br>or,  with w2=1\n","* x2 = -w1*x1 - w0"]},{"metadata":{"id":"ZgfA-11cxh26","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","---\n","\n","## ... try with some coefficients..."]},{"metadata":{"id":"VO5lM1UalGwB","colab_type":"text"},"cell_type":"markdown","source":["### <font color= #b717ab>?? ... plot the line (hyper plane)...."]},{"metadata":{"id":"X7GdsZI1n-7z","colab_type":"code","colab":{}},"cell_type":"code","source":["# TO DO...\n","\n","w2=1\n","\n","w0=5\n","w1=1\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LeN549YeoWoO","colab_type":"text"},"cell_type":"markdown","source":["#<font color= #b717ab>?? ... \"where\" is the [w1, w2] vector??...."]},{"metadata":{"id":"GzdPjZtzqbdi","colab_type":"code","colab":{}},"cell_type":"code","source":["# TRY plot the [w1,w2] vector in the scatter plot\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MkXt37LNhH12","colab_type":"text"},"cell_type":"markdown","source":["### Classification based on the distance to the line\n","\n","* w2\\*x2 + w1\\*x1 + w0 > 0  'green' points\n","* w2\\*x2 + w1\\*x1 + w0 < 0  'blue' points\n"]},{"metadata":{"id":"f7Qyfo63rO-Y","colab_type":"code","colab":{}},"cell_type":"code","source":["train_X = np.vstack((group1, group2))\n","\n","# make \"predictions\" of class 0 or 1\n","# pred = w2*x2 + w1*x1 + w0"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iGKfUVO-rGvQ","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","plt.figure(figsize=(9,6))\n","plt.plot(pred)\n","plt.xlabel('x1',fontsize=18)\n","plt.ylabel('x2',fontsize=18)\n","plt.title('Classification: < 0 \\'blue\\' > 1 \\'green\\' ',fontsize=18)\n","plt.grid(color='k', linestyle='--')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Jvyg0F60hH2D","colab_type":"text"},"cell_type":"markdown","source":["### let's make these values \"probabilities\" using the $sigmoid$ function"]},{"metadata":{"id":"VBU58W5ihH2F","colab_type":"code","colab":{}},"cell_type":"code","source":["x = np.arange(-10, 11)\n","plt.title('Sigmoid : logistic function',fontsize=18)\n","plt.xlabel('$x$')\n","plt.ylabel('$p(X)=1/(1+exp(-x))$',fontsize=16)\n","plt.plot(x, (1/(1+np.exp(-x))));\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O2oyzikyhH2V","colab_type":"text"},"cell_type":"markdown","source":["####     Prediction using the $logistic$ or $sigmoid$ function \n","* $p(X) = 1/(1 + \\exp(x))$, taking values between $0$ and $1$.\n","\n","* $p(X)$ represents the probability that the point $X$ should be labelled \"green\".\n"]},{"metadata":{"id":"HwzT1SA5vN2j","colab_type":"text"},"cell_type":"markdown","source":["#<font color= #b717ab>?? apply sigmoid to our predictions in \"pred\".... and plot!"]},{"metadata":{"id":"a8u1grfzv_ZW","colab_type":"code","colab":{}},"cell_type":"code","source":["# TO DO..."],"execution_count":0,"outputs":[]},{"metadata":{"id":"vqi9-4lnhH2k","colab_type":"text"},"cell_type":"markdown","source":["# NOW let's use cross-entropy loss function\n","$$-\\sum_{i=1}^n l(X_i) \\log(p(X_i)) + (1-l(X_i))\\log(1-p(X_i)),$$\n","<br>\n","where $l(X_i)$ is the label of $X_i$ (which is $0$ for 'blue' or $1$ for 'green').\n"]},{"metadata":{"id":"xBjPtk2fhH2l","colab_type":"code","colab":{}},"cell_type":"code","source":["train_labels = np.array([0.0] * Ndata_class + [1.0] * Ndata_class)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"P6iPd00PwhCB","colab_type":"text"},"cell_type":"markdown","source":["#<font color= #b717ab>?? can you obtain the cross-entropy loss function ?"]},{"metadata":{"id":"dal6wSj6wrlP","colab_type":"code","colab":{}},"cell_type":"code","source":["# Cost function is cross-entropy\n","# TO DO...\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cTSyggf-xG2K","colab_type":"text"},"cell_type":"markdown","source":["#<font color= #b717ab>?? ... and now the more interprtable Accuraccy (Classification Error)"]},{"metadata":{"id":"TUhc303LxXWU","colab_type":"code","colab":{}},"cell_type":"code","source":["# TO DO : acuraccy\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"l9iUnBLChH28","colab_type":"text"},"cell_type":"markdown","source":["---\n","\n","\n","\n","---\n","\n","## Now we will use <font color= #FF5733 >TensorFlow</font> (using graphs) for:\n","\n","- ## Feeding data into a \"given\" linear classifier with $sigmoid$ output"]},{"metadata":{"id":"dgDowBWyzFzL","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","## first import TensorfLow"]},{"metadata":{"id":"fstdzR9AzE6m","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sXg5nqW9hH2_","colab_type":"code","colab":{}},"cell_type":"code","source":["### GRAPH DEFINITION\n","\n","# PLACEHOLDERS:\n","# Inputs are now two-dimensional and come with labels \"blue\" or \"green\" (represented by 0 or 1)\n","X = tf.placeholder(\"float\", shape=[None, 2])\n","labels = tf.placeholder(\"float\", shape=[None])\n","\n","\n","# Set model weights and bias as before\n","#W = tf.Variable(tf.ones([2, 1], \"float\"), name=\"weight\")\n","#b = tf.Variable(tf.zeros([1], \"float\"), name=\"bias\")\n","\n","\n","W=tf.constant([w1,w2],\"float\",shape=[2,1],name=\"weights\")\n","b=tf.constant(np.float(w0),\"float\",name=\"bias\")\n","\n","\n","# Predictor is now the logistic function\n","pred_tf = tf.sigmoid(tf.to_double(tf.reduce_sum(tf.matmul(X, W),1)+b))\n","\n","# Cost function is cross-entropy\n","cost_tf = -tf.reduce_sum(tf.to_double(labels) * tf.log(pred_tf) + (1-tf.to_double(labels)) * tf.log(1-pred_tf))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DlF8ZrygylWF","colab_type":"text"},"cell_type":"markdown","source":["### you can see details of [tf.reduce_sum](https://www.tensorflow.org/api_docs/python/tf/reduce_sum)\n","\n","    Computes the sum of elements across dimensions of a tensor."]},{"metadata":{"id":"ukjgwui3hH3G","colab_type":"code","colab":{}},"cell_type":"code","source":["### GRAPH EXECUTION\n","\n","# Initializing the variables\n","init = tf.global_variables_initializer()\n","#init = tf.initialize_all_variables()\n","\n","# We stack our two groups of 2-dimensional points\n","train_X = np.vstack((group1, group2))\n","\n","# labels to feed them\n","train_labels = np.array([0.0] * Ndata_class + [1.0] * Ndata_class)\n","\n","\n","with tf.Session() as sess:\n","    \n","    sess.run(init)\n","    \n","    pred_out, cost_out=sess.run([pred_tf, cost_tf], feed_dict={X: train_X, labels: train_labels})\n","\n","        "],"execution_count":0,"outputs":[]},{"metadata":{"id":"9N55Adv8hH3P","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"cross-entropy: {}\".format(cost_out))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I3ysOnxThH3m","colab_type":"code","colab":{}},"cell_type":"code","source":["Accuracy=np.sum((pred_out>0.5).astype(int) == train_labels)/(len(pred_out)*1.0)\n","\n","print(\"Classification Accuracy = \",Accuracy)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cv-m0wbDhH3s","colab_type":"text"},"cell_type":"markdown","source":["# Now let's train!\n","\n","\n","\n","*   Both $W$ and $b$ are now <font size=4 color=green> variables</font>\n","\n","\n"]},{"metadata":{"id":"m__uHgZ5hH3t","colab_type":"code","colab":{}},"cell_type":"code","source":["# Inputs are now two-dimensional and come with labels \"blue\" or \"green\" (represented by 0 or 1)\n","X = tf.placeholder(\"float\", shape=[None, 2])\n","labels = tf.placeholder(\"float\", shape=[None])\n","\n","# Set model weights and bias as before\n","W = tf.Variable(tf.zeros([2, 1], \"float\"), name=\"weight\")\n","b = tf.Variable(tf.zeros([1], \"float\"), name=\"bias\")\n","\n","# Predictor is now the logistic function\n","pred_tf = tf.sigmoid(tf.to_double(tf.reduce_sum(tf.matmul(X, W),1) + b))\n","\n","\n","# Cost function is cross-entropy\n","cost_tf = -tf.reduce_sum(tf.to_double(labels) * tf.log(pred_tf) + (1-tf.to_double(labels)) * tf.log(1-pred_tf))\n","\n","# Gradient descent\n","learning_rate = 0.00001\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_tf)\n","\n","# Initializing the variables\n","init = tf.global_variables_initializer()\n","#init = tf.initialize_all_variables()\n","\n","# We stack our two groups of 2-dimensional points\n","train_X = np.vstack((group1, group2))\n","\n","# labels to feed them\n","train_labels = np.array([0.0] * Ndata_class + [1.0] * Ndata_class)\n","\n","\n","with tf.Session() as sess:\n","    sess.run(init)\n","    \n","    # We can Run the optimization algorithm several times\n","    for i in range(10):\n","        \n","        cost_out,W_out,b_out,pred_out,_=sess.run([cost_tf, W,b, pred_tf, optimizer], feed_dict={X: train_X, labels: train_labels})\n","        print(\"\\n***** Epoch : %d \\n Cost= %s \"%(i,cost_out))\n","        print(\"Weights= \",format(W_out))\n","        print(\"bias= \",format(b_out))\n","        \n","        Accuracy=np.sum((pred_out>0.5).astype(int) == train_labels)/(len(pred_out)*1.0)\n","\n","        print(\"Classification Accuracy = \",Accuracy)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WQfPDBCRhH4G","colab_type":"text"},"cell_type":"markdown","source":["### Now we train using batches\n"]},{"metadata":{"id":"Bpe9JNc-hH4K","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.cm as cm\n","import seaborn as sns\n","\n","n_samples=Ndata_class*2\n","batch_size=40\n","\n","with tf.Session() as sess:\n","    # We stack our two groups of 2-dimensional points and label them 0 and 1 respectively\n","    train_X = np.vstack((group1, group2))\n","\n","    # labels to feed them\n","    train_labels = np.array([0.0] * Ndata_class + [1.0] * Ndata_class)\n","\n","\n","    sess.run(init)\n","\n","    # Run the optimization algorithm 1000 times\n","    for i in range(1000):\n","        # Select random minibatch\n","        indices = np.random.choice(n_samples, batch_size)\n","        X_batch, labels_batch = train_X[indices], train_labels[indices]\n","        sess.run(optimizer, feed_dict={X: X_batch, labels: labels_batch})\n","\n","        \n","    # Plot the predictions: the values of p\n","    Xmin = np.min(train_X)-1\n","    Xmax = np.max(train_X)+1\n","    x = np.arange(Xmin, Xmax, 0.1)\n","    y = np.arange(Xmin, Xmax, 0.1)\n","    \n","\n","    plt.scatter(group1.T[0][:],group1.T[1][:])\n","    plt.scatter(group2.T[0][:],group2.T[1][:],color='g')\n","    plt.xlim(Xmin, Xmax)\n","    plt.ylim(Xmin, Xmax)\n","    print('W = ', sess.run(W))\n","    print('b = ', sess.run(b))\n","    \n","    xx, yy = np.meshgrid(x, y)\n","    predictions = sess.run(pred_tf, feed_dict={X: np.array((xx.ravel(), yy.ravel())).T})\n","    \n","    plt.title('Probability that model will label a given point \"green\"')\n","    plt.contour(x, y, predictions.reshape(len(x), len(y)), cmap=cm.BuGn, levels=np.arange(0.0, 1.1, 0.1))\n","    plt.colorbar()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J0nALdxAhH4V","colab_type":"text"},"cell_type":"markdown","source":["## Logistic regression in TensorFlow\n","\n","https://gist.github.com/fuglede/ad04ce38e80887ddcbeb6b81e97bbfbc\n","\n"]},{"metadata":{"id":"07wEoayZhH4W","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}